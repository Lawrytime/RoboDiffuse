# RoboDiffuse

<table>
  <tr>
    <td align="center">
      <img src="https://github.com/Lawrytime/RoboDiffuse/blob/main/assets/Generated%20Motions/Extend%20to%20top%20Left%20Diagonal%20-%20Generated.gif" width="400">
      <p>Extend to top Left Diagonal</p>
    </td>
    <td align="center">
      <img src="https://github.com/Lawrytime/RoboDiffuse/blob/main/assets/Generated%20Motions/Extend%20to%20top%20Right%20Diagonal%20-%20Generated.gif" width="400">
      <p>Extend to top Right Diagonal</p>
    </td>
  </tr>
</table>


## Disclaimer 

This work is produced by Timilehin Olusegun, under the supervision of Prof. Jonathan Loo, for MSc in Artificial Intelligence at the University of West London.

## Introduction

The RoboDiffuse model stems from a compelling endeavor to bridge the gap between human natural language and robotic motion generation. In a world where robotics is rapidly evolving, having a robotic system that understands and accurately interprets human commands into precise motions is pivotal. This model is a stride towards enhancing the intuitive interaction between humans and robots, paving the way for more dynamic and responsive robotic systems.


## Model Overview

RoboDiffuse employs advanced diffusion processes alongside a transformer encoder to translate high-level textual descriptions into a series of robotic arm motions. The core of the model is grounded on a diffusion process that refines the motion predictions generated by the transformer encoder, ensuring a smooth and accurate transition from text to motion.

The model architecture integrates a transformer encoder that digests textual descriptions and generates initial motion sequences. These sequences are further refined by a diffusion process, ensuring the generated motions are coherent and reflective of the input textual descriptions. The entire model is conditioned on CLIP-based textual embeddings which encapsulate the semantic essence of the input text, facilitating a more accurate translation into robotic motions.

![](https://github.com/Lawrytime/RoboDiffuse/blob/main/assets/RoboDiffuse.png)


## Key Features

  - Text-to-Motion Translation: RoboDiffuse is adept at translating high-level textual instructions into precise robotic arm motions, facilitating intuitive human-robot interaction.

  - Diffusion Process Refinement: The integration of a diffusion process refines the generated motion sequences, ensuring they are smooth and accurately reflective of the textual instructions.

  - CLIP-based Textual Embedding: The model leverages CLIP-based textual embeddings to capture the semantic nuances of the input text, which significantly enhances the accuracy of the text-to-motion translation.


### Prompting

<td align="center">
      <img src="https://github.com/Lawrytime/RoboDiffuse/blob/main/assets/Generated%20Motions/45_Degrees_to_the_Left%20-%20Generated.gif" width="600">
    </td>




![](assets/Generated%20Motions/Perform%20360%20Clockwise%20-%20Generated.gif)
